# GLMの尤度比検定と検定の非対称性

## 帰無仮説

棄却されるための仮設。

## 対立仮説

帰無仮設が棄却された時に採用される仮説。

## 検定統計量

モデルの当てはまりの良さなど、検定で分布を調べる量。

## 有意水準

1 - (検定統計量の取り得る「ありがちな範囲」と決めた量)
0.05がよく使われる。

## Neyman-Pearsonの検定のわくぐみ

「帰無仮説が正しい」という命題が否定できるかどうかのみを調べる。
対立仮設のモデルで得られた検定統計量が、「ありがちな範囲」をはみ出ているか調べる。
はみ出ていれば帰無仮説は棄却されて対立仮設が支持される。

## 尤度比

L1 * / L2 * = 帰無仮説の最大尤度 / 対立仮設の最大尤度

## 逸脱度の差

尤度比検定では尤度比の対数を取り、-2をかける。
すると、逸脱度の差になる。

ΔD1,2 = -2 (log L1 * - log L2 * )

## 尤度比検定

尤度比を使った検定。

## 第一種の過誤

本当は帰無仮説の方が真のモデルなのに、帰無仮説を棄却してしまい、対立仮設を正しいとしてしまう過誤。
Neyman-Pearsonの検定のわくぐみではこの過誤の検討にだけ専念する。

## 第二種の過誤

帰無仮説が真のモデルでないのに、対立仮設を意味もなく複雑なモデルだと判断して、帰無仮説を正しいとしてしまう過誤。

## P値

第一種の過誤をおかす確率。

## パラメトリックブートストラップ法

尤度比検定をするとする。
いかなるめんどうな状況でもP値が計算できる。
帰無仮説を真のモデルだと仮定して、乱数を使ってデータをシミュレーションする。

まず、各仮説のモデルについて逸脱度の差を計算する。
次に帰無仮説を真のモデルだと仮定して、データをシミュレーションする。
シミュレートしたデータに対して、各仮説のモデルを当てはめ、逸脱度の差を計算する。
このシミュレーションを繰り返すことで、逸脱度の差の分布が得られる。
シミュレートした逸脱度の差のうち、本物のデータでの逸脱度の差を超える物が何個あるか数え、確率を計算する。
すると、その確率がP値になる。

## χ2分布を使った近似計算

サンプルサイズが大きい場合は逸脱度の差は自由度1のχ2分布で近似できる。

## 「帰無仮説を棄却できない」は「差がない」ではない

帰無仮説が棄却できない時は「帰無仮説が正しい」とは言えない。
帰無仮説も対立仮設も正しいとも正しくないとも言えない。

## デモ

### パラメトリックブーストラップ法のサンプル

[bootstrap-sample.R](https://github.com/YuichiroSato/DataScience/blob/master/KuboTakuya/chapter-05/bootstrap-sample.R)では、パラメトリックブートストラップ法を使って尤度比検定をやるサンプルを見れるようにした。
データは指数関数をリンク関数として持つポアソン分布からサンプリングした。
検定はデータと `x` の相関の強弱とデータサイズの大小で4種類の場合についてやった。
帰無仮説は棄却されたり、されなかったりする。。
だいたいの傾向として相関が強くてデータの数が多い方が検定は成功しやすい。 
帰無仮説が棄却されない場合は、このデータでは何も結論できないという意味。
状況をプロットもしているが、だいたい帰無仮説が棄却できない時は対立仮説も帰無仮説も同じような曲線になっている場合である。

### パラメトリックブートストラップ法のサンプル２

[plot-bootstrap.R](https://github.com/YuichiroSato/DataScience/blob/master/KuboTakuya/chapter-05/plot-bootstrap.R)ではパラメトリックブートストラップ法でデータをシミュレートする様子を見られるようにした。
実行するとポアソン分布からサンプリングしたサンプルデータに対してパラメトリックブートストラップ法を使って尤度比検定をする。
そしてグラフを３つプロットする。
１枚目はサンプルデータと、データにポアソン回帰をした結果の帰無仮説と対立仮説の曲線をプロットしている。
２枚目はパラメトリックブートストラップ法でシミュレートしたサンプルをプロットして、そのサンプルにポアソン回帰した帰無仮説と対立仮設をプロットしている。
３枚目はポアソン回帰で得た対立仮説のパラメータを使って、サンプルをシミュレートして、そのサンプルにポアソン回帰した帰無仮説と対立仮説をプロットしている。
だいたいの傾向として、２枚目は帰無仮説も対立仮説も似たような曲線になる。
３枚目は対立仮説がちゃんと曲線になる。
最初のポアソン回帰は `x` に相関のあるデータについてやっているので、対立仮説は曲線になるし、当てはまりもよくなる。
ブートストラップ法のシミュレーションでは帰無仮説のパラメータを使っているので、 `x` に相関の無いデータが生成されて、めったなことじゃ最初のポアソン回帰と同じ尤度の違いが生まれない。
よってP値が計算できて、検定ができる。

### 帰無仮説を棄却できない場合の例

[show-fail-to-reject.R](https://github.com/YuichiroSato/DataScience/blob/master/KuboTakuya/chapter-05/show-fail-to-reject.R)ではパラメトリックブートストラップ法の実行結果を10回プロットしている。
有意水準として5%を設定するなら、P値が0.05以上だと帰無仮説を棄却できないのだが、今の場合は10回やると1回くらいはこういう場合が見つかる。
棄却できる時は帰無仮説の曲線と対立仮説の曲線は形が違うが、できない時はどっちも直線に近い形になる。
データは `x` に相関のある分布から生成されているが、たまたまデータが偏っていると最尤推定で `x` と相関のないようなパラメータを推定してしまう場合があるわけである。

### 帰無仮説が棄却できない比率

[plot-fail-to-reject.R](https://github.com/YuichiroSato/DataScience/blob/master/KuboTakuya/chapter-05/plot-fail-to-reject.R)ではパラメトリックブートストラップ法で帰無仮説を棄却できない場合がどれくらいの比率で表れるのかを、プロットしてみた。
最尤推定を100 * 100 * 4回やるので結構時間がかかる。
データの数が多くなって `x` との相関が強いほど棄却できなくなる場合はなくなるのが分かる。