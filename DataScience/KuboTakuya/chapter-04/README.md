# GLMのモデル選択の読書メモ

## 最大対数尤度

最尤推定の時の対数尤度。

## 逸脱度

D = -2logL* (logL* は最大対数尤度)

## 残差逸脱度

D - (full modelの逸脱度)

## full model

ポアソン分布モデルで可能な最小逸脱度を与えるモデル。
データ数と同じ個数のパラメータを使ったモデル。

## null model

パラメータ数1のモデル。
最大の逸脱度を与える。

## AIC

複数のモデルから良いモデルを選択する基準の一つ。
最尤推定したパラメータの数がk個の時のAICは

AIC = -2 (logL* - k)
= D + 2k

AICが一番小さいモデルが良いモデル。

## 平均対数尤度

最尤推定して得られたパラメータを、真の分布から新たにデータを作って対数尤度を計算して平均したもの。
実際の問題では真の分布は不明なのだから、簡単には計算できない。

## バイアス

最大尤度 - 平均対数尤度

最大尤度は、あるデータに過度にフィットしているので、平均よりよくフィットしている場合がある。
機械学習で言うところの過学習。
その差がバイアス。

## デモ

### 推定のずれ

[plot-regression.R](https://github.com/YuichiroSato/DataScience/blob/master/KuboTakuya/chapter-04/plot-regression.R)ではデータ数の少ないポアソン回帰をやってみて、どれくらい真の値から推定がずれるのかを見た。
推定に使うデータは平均4のポアソン分布からサンプリングした5個のデータである。
コードを実行すると、サンプリングと最尤推定を行い、結果をプロットすることを10回くりかえす。
だいたい10回推定すると、1回くらい目に見えておかしな推定をするのが分かる。
このように、無限のデータを用意することができない以上、推定は推定でしかなく真の値からどうしてもずれる。

### 推定のずれのヒストグラム

[plot-estimation.R](https://github.com/YuichiroSato/DataScience/blob/master/KuboTakuya/chapter-04/plot-estimation.R)では推定のずれの分布をヒストグラムにしてみた。
推定に使うデータは、やはり平均4のポアソン分布からサンプリングしたものである。
データの数が増えるにしたがって、推定結果は真の値である4の周囲に集中するが、データ数200になってもはやりずれる時はずれるのが分かる。

### バイアスのデモ

[plot-bias.R](https://github.com/YuichiroSato/DataScience/blob/master/KuboTakuya/chapter-04/plot-bias.R)ではバイアスとAICについて理解が深まるような数値計算をした。
説明変数には`x`と`c`の2種類を用意した。
これらの変数がポアソン分布の平均`λ`に影響したりしなかったりする複数の場合を用意して、ポアソン回帰してみて複数のモデルで尤度やバイアスを見てみる。

データとリンク関数は4種類用意した。
サンプリングの分布は以下の4種類である。
説明変数に無関係に平均4、`x`だけに依存、`c`だけに依存、`x`と`c`の両方に依存、の4種類である。

```
function(x, c) rpois(dataSize, lambda = 4)
function(x, c) rpois(dataSize, lambda = exp(0.1 + 0.2 * x))
function(x, c) rpois(dataSize, lambda = exp(0.1 + 0.2 * c))
function(x, c) rpois(dataSize, lambda = exp(0.1 + 0.2 * x + 0.2 * c))
```

ポアソン回帰をしているのは以下のコードで、説明変数なし、`x`だけ、`c`だけ、`x`と`c`の両方を使う、の4つの場合について回帰をした。

```
fit1 <- glm(formula = y ~ 1, family = poisson, data = d)
fit2 <- glm(formula = y ~ x, family = poisson, data = d)
fit3 <- glm(formula = y ~ c, family = poisson, data = d)
fit4 <- glm(formula = y ~ x + c, family = poisson, data = d)
```

後は、こうして推定したパラメータに対して、サンプリングに使ったのと同じ分布から新たにデータを取って、平均対数尤度を計算し、最大対数尤度との差を計算してバイアスを求めた。
これを1000回繰り返して、バイアスの平均、最大対数尤度の平均、平均対数尤度の平均を出力した。

実行には結構時間がかかるので、実行結果をここに貼っておく。


indipendent data

|                    | null      | x         | c         | xc        |
|--------------------|-----------|-----------|-----------|-----------|
|log likelihood      | -208.2121 | -207.6975 | -207.7117 | -207.1934 |
|mean log likelihood | -209.1973 | -209.6974 | -209.697  | -210.2701 |
|bias                | 0.985136  |  1.999856 | 1.985335  |  3.076757 |

correlated X data

|                    | null      | x         | c         | xc        |
|--------------------|-----------|-----------|-----------|-----------|
|log likelihood      | -244.4398 | -191.5793 | -243.3975 | -191.1035 |
|mean log likelihood | -247.0061 | -193.4747 | -248.0147 | -193.9862 |
|bias                | 2.566339  | 1.89539   | 4.617209  | 2.882704  |

correlated C data

|                    | null      | x         | c         | xc        |
|--------------------|-----------|-----------|-----------|-----------|
|log likelihood	     | -245.2526 | -244.1011 | -191.4285 | -190.9154 |
|mean log likelihood | -246.9949 | -248.1054 | -193.434  | -193.9483 |
|bias                | 1.742317  | 4.004258  | 2.005497  | 3.032951  |

correlated XC data

|                    | null      | x         | c         | xc        |
|--------------------|-----------|-----------|-----------|-----------|
|log likelihood	     | -582.0412 | -410.6317 | -409.471  | -243.1936 |
|mean log likelihood | -591.6911 | -421.5608 | -421.3756 | -246.74   |
|bias                | 9.649996  | 10.92918  | 11.90459  | 3.546357  |


どのデータに対しても、`x`と`c`の両方を説明変数に使った場合が一番最大対数尤度は大きくなるのが分かる。
真の分布が`x`と`c`の両方に依存する場合はこれでいいのだけれど、それ以外の場合は困る。
これは、役に立たない変数でも、モデルの変数を増やせば過学習を起こして、データへの当てはまりが良くなるからである。

真の分布が`x`または`c`だけに依存する場合は、対数尤度に大きな差があるので、説明変数として`x`または`c`のどちらを選べばいいかは簡単に分かる。
しかし、`x`と`c`の両方を説明変数に持つモデルの方が、やはり対数尤度が大きくなる。
バイアスを見ると、変数が多いモデルの方がバイアスが大きくなっているのが分かる。
これにより、変数の多いモデルは過学習を起こしているために、尤度が大きくなっているだけだと考えられる。

対数尤度の差も0.5くらいしか離れていないから、変数を増やすことによるAICの増加と割が合わないのが分かる。
AICを使えば、不必要に変数を増やさないようなモデルを選べるのが分かる。
